{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82afa046-7db8-4f4d-a992-20a0718a8c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from catboost import Pool, CatBoostRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, PolynomialFeatures\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from torchvision import transforms\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c2ba4c-d15b-4e00-a708-611e96e3eb45",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    def __init__(self):\n",
    "        self.target_columns = ['X4_mean', 'X11_mean', 'X18_mean', 'X26_mean', 'X50_mean', 'X3112_mean']\n",
    "        self.n_val_samples = 4096\n",
    "        self.seed = 999\n",
    "        self.device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "def set_seed(seed_value: int):\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed_value)\n",
    "    np.random.seed(seed_value)\n",
    "    torch.manual_seed(seed_value)\n",
    "    torch.cuda.manual_seed(seed_value)\n",
    "\n",
    "# Initialize config and seed\n",
    "CONFIG = Config()\n",
    "set_seed(CONFIG.seed)\n",
    "\n",
    "print(f\"Currently using device: {CONFIG.device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1b68e3-8091-4c13-8e57-499931001419",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths\n",
    "base_path = 'C:/Users/vince/PyCharmProjects/cs680'\n",
    "dataset_path = os.path.join(base_path, 'data/cs-480-2024-spring/data')\n",
    "train_img_dir = os.path.join(dataset_path, 'train_images')\n",
    "test_img_dir = os.path.join(dataset_path, 'test_images')\n",
    "\n",
    "print(\"Paths defined\")\n",
    "\n",
    "# Load data\n",
    "train_fullset = pd.read_csv(os.path.join(dataset_path, 'train.csv'))\n",
    "train_fullset['file_path'] = train_fullset['id'].apply(lambda s: os.path.join(train_img_dir, f'{s}.jpeg'))\n",
    "print(train_fullset.head(2).to_string())\n",
    "\n",
    "test = pd.read_csv(os.path.join(dataset_path, 'test.csv'))\n",
    "test['file_path'] = test['id'].apply(lambda s: os.path.join(test_img_dir, f'{s}.jpeg'))\n",
    "print(test.head(2).to_string())\n",
    "print(\"Data loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b35d727-29d5-4cb6-965e-4c1de9059d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG.FEATURE_COLUMNS = test.columns.values[1:-1]\n",
    "\n",
    "train, val = train_test_split(train_fullset, test_size=CONFIG.n_val_samples, shuffle=True, random_state=CONFIG.seed)\n",
    "train = train.reset_index(drop=True)\n",
    "val = val.reset_index(drop=True)\n",
    "\n",
    "print(\"Train-validation split complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c3507e7-f9c6-460a-861e-dd117a314bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_mask(dataframe, stats_df):\n",
    "    mask_array = np.empty(shape=dataframe[CONFIG.target_columns].shape, dtype=bool)\n",
    "\n",
    "    for index, column in enumerate(CONFIG.target_columns):\n",
    "        column_values = dataframe[column].values\n",
    "        lower_bound = stats_df.loc[column]['0.1%']\n",
    "        upper_bound = stats_df.loc[column]['99%']\n",
    "        mask_array[:, index] = (column_values > lower_bound) & (column_values < upper_bound)\n",
    "\n",
    "    return mask_array.all(axis=1)\n",
    "\n",
    "labels_describe_df = train[CONFIG.target_columns].describe(percentiles=[0.001, 0.99]).round(3).T\n",
    "\n",
    "mask_train = generate_mask(train, labels_describe_df)\n",
    "mask_val = generate_mask(val, labels_describe_df)\n",
    "\n",
    "train_mask = train[mask_train].reset_index(drop=True)\n",
    "val_mask = val[mask_val].reset_index(drop=True)\n",
    "\n",
    "for mask, subset_name, data in zip([train_mask, val_mask], ['train', 'val'], [train, val]):\n",
    "    subset_size = len(data)\n",
    "    masked_count = subset_size - len(mask)\n",
    "    masked_percentage = (masked_count / subset_size) * 100\n",
    "\n",
    "feature_scaler = StandardScaler()\n",
    "train_features_scaled = feature_scaler.fit_transform(train_mask[CONFIG.FEATURE_COLUMNS].values.astype(np.float32))\n",
    "val_features_scaled = feature_scaler.transform(val_mask[CONFIG.FEATURE_COLUMNS].values.astype(np.float32))\n",
    "test_features_scaled = feature_scaler.transform(test[CONFIG.FEATURE_COLUMNS].values.astype(np.float32))\n",
    "\n",
    "y_train_scaled = train_mask[CONFIG.target_columns].values\n",
    "y_val_scaled = val_mask[CONFIG.target_columns].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf0ffb8-eded-447e-a497-2b2b50ec9c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_image_embeddings(model, preprocess_pipeline, batch_size, dataframe):\n",
    "    embeddings = []\n",
    "    for start_idx in tqdm(range(0, len(dataframe), batch_size)):\n",
    "        batch_paths = dataframe['file_path'][start_idx:start_idx + batch_size]\n",
    "        batch_images = [preprocess_pipeline(Image.open(path)) for path in batch_paths]\n",
    "        image_tensor = torch.stack(batch_images).to(CONFIG.device)\n",
    "        with torch.no_grad():\n",
    "            batch_embeddings = model(image_tensor)\n",
    "        embeddings.extend(batch_embeddings.cpu().numpy())\n",
    "    return embeddings\n",
    "\n",
    "model = torch.hub.load('facebookresearch/dinov2', 'dinov2_vitg14_reg').to(CONFIG.device)\n",
    "model.eval()\n",
    "preprocess_pipeline = transforms.Compose([\n",
    "    transforms.Resize(224, interpolation=3),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "])\n",
    "\n",
    "batch_size = 64\n",
    "file_suffix = 'image_embs_dinov2_vitg14_reg'\n",
    "train_image_embeddings = extract_image_embeddings(model, preprocess_pipeline, batch_size, train_mask)\n",
    "np.save(f'train_{file_suffix}', np.array(train_image_embeddings))\n",
    "val_image_embeddings = extract_image_embeddings(model, preprocess_pipeline, batch_size, val_mask)\n",
    "np.save(f'val_{file_suffix}', np.array(val_image_embeddings))\n",
    "test_image_embeddings = extract_image_embeddings(model, preprocess_pipeline, batch_size, test)\n",
    "np.save(f'test_{file_suffix}', np.array(test_image_embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1b2d78-79fe-450a-901b-be475b1283bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_features = 2000\n",
    "\n",
    "train_poly_feats = PolynomialFeatures(2).fit_transform(train_features_scaled)[:, :poly_features]\n",
    "train_features_mask_all = np.concatenate((train_poly_feats, train_image_embeddings), axis=1)\n",
    "\n",
    "val_poly_feats = PolynomialFeatures(2).fit_transform(val_features_scaled)[:, :poly_features]\n",
    "val_features_mask_all = np.concatenate((val_poly_feats, val_image_embeddings), axis=1)\n",
    "\n",
    "test_poly_feats = PolynomialFeatures(2).fit_transform(test_features_scaled)[:, :poly_features]\n",
    "test_features_all = np.concatenate((test_poly_feats, test_image_embeddings), axis=1)\n",
    "\n",
    "train_features_mask_df = pd.DataFrame(train_features_mask_all)\n",
    "train_features_mask_df['emb'] = train_image_embeddings\n",
    "\n",
    "val_features_mask_df = pd.DataFrame(val_features_mask_all)\n",
    "val_features_mask_df['emb'] = val_image_embeddings\n",
    "\n",
    "test_features_mask_df = pd.DataFrame(test_features_all)\n",
    "test_features_mask_df['emb'] = test_image_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad83a0f-2101-4311-abcf-94725aee3a1a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "models = {}\n",
    "scores = {}\n",
    "for i, col in tqdm(enumerate(CONFIG.target_columns), total=len(CONFIG.target_columns)):\n",
    "    y_curr = y_train_scaled[:, i]\n",
    "    y_curr_val = y_val_scaled[:, i]\n",
    "    train_pool = Pool(train_features_mask_df, y_curr, embedding_features=['emb'])\n",
    "    val_pool = Pool(val_features_mask_df, y_curr_val, embedding_features=['emb'])\n",
    "    \n",
    "    model = CatBoostRegressor(iterations=2500, learning_rate=0.06, loss_function='RMSE', verbose=1000, random_state=CONFIG.seed)\n",
    "    model.fit(train_pool, eval_set=val_pool, use_best_model=True, early_stopping_rounds=100)\n",
    "    models[col] = model\n",
    "\n",
    "    y_train_pred = model.predict(train_pool)\n",
    "    y_curr_val_pred = model.predict(val_pool)\n",
    "    \n",
    "    mae = mean_absolute_error(y_curr, y_train_pred)\n",
    "    r2 = r2_score(y_curr, y_train_pred)\n",
    "    val_mae = mean_absolute_error(y_curr_val, y_curr_val_pred)\n",
    "    r2_col = r2_score(y_curr_val, y_curr_val_pred)\n",
    "    loss = mae\n",
    "    val_loss = val_mae\n",
    "\n",
    "    scores[col] = {\n",
    "        'MAE': mae,\n",
    "        'R2' : r2,\n",
    "        'val_MAE': val_mae,\n",
    "        'val_R2': r2_col,\n",
    "        'loss': loss,\n",
    "        'val_loss': val_loss\n",
    "    }\n",
    "    print(f'Target: {col} | MAE: {mae:.3f} | val_MAE: {val_mae:.3f} |r2: {r2:.3f}| val_R2: {r2_col:.3f} | loss (MAE): {loss:.3f} | val_loss (MAE): {val_loss:.3f}')\n",
    "\n",
    "mean_scores = {\n",
    "    'MAE': np.mean([score['MAE'] for score in scores.values()]),\n",
    "    'R2': np.mean([score['R2'] for score in scores.values()]),\n",
    "    'val_MAE': np.mean([score['val_MAE'] for score in scores.values()]),\n",
    "    'val_R2': np.mean([score['val_R2'] for score in scores.values()])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d9c286-1380-43a5-96e4-2bbe6d9350f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'id': test['id']})\n",
    "submission[CONFIG.target_columns] = 0\n",
    "submission.columns = submission.columns.str.replace('_mean', '')\n",
    "\n",
    "for i, col in enumerate(CONFIG.target_columns):\n",
    "    test_pool = Pool(test_features_mask_df, embedding_features=['emb'])\n",
    "    col_pred = models[col].predict(test_pool)\n",
    "    submission[col.replace('_mean', '')] = col_pred\n",
    "\n",
    "submission_file = os.path.join(base_path, f'submission_{int(time.time())}.csv')\n",
    "submission.to_csv(submission_file, index=False)\n",
    "\n",
    "print(f\"\\nSubmission saved to: {submission_file}\")\n",
    "print(\"\\nSubmission head:\")\n",
    "print(submission.head().to_string())\n",
    "\n",
    "print(\"\\nSubmission column ranges:\")\n",
    "for col in submission.columns[1:]:  # Skip the 'id' column\n",
    "    print(f\"{col}: [{submission[col].min():.3f}, {submission[col].max():.3f}]\")\n",
    "\n",
    "print(\"Script completed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4526facd-2a28-4386-b4fa-2722e993fe49",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
